---
layout: post
title:  "[cs231n] Lecture 2: 컴퓨터는 사진을 알아볼 수 없다"
date:   2022-08-10 12:00:00 +0800
category: studylog
tags: [blog, cs231n]
comments: true
use_math: true
img:
    path: /assets/img/
---

![quotes](/assets/img/quotation_mark.jpeg){: width="30"}{:style="display:block; margin-left:auto; margin-right:auto; margin-bottom:3px"}
## 컴퓨터는 사진을 알아볼 수 없다
{:style="text-align:center; margin-top:0px; margin-bottom:30px"}

![cat](/assets/img/2022-08-10/cat.png){: width="200"}{:style="display:block; margin-left:auto; margin-right:auto; padding:5px"}

&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;위 사진은 무엇에 대한 사진일까요? 아마 4살짜리 제 조카에게 물어봐도 고양이라고 대답할 수 있을 겁니다. 대답하기 어려운 질문은 아니죠. 그런데 불과 몇 년 전까지만 해도, 컴퓨터는 이 사진이 고양이인지 잘 맞추지 못했습니다. 컴퓨터는 사람보다 훨씬 빠르게 계산할 수 있는데, 왜 간단한 고양이 사진은 잘 알아보지 못했던 걸까요?
{:style="opacity: 0.90"}

&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;다시 돌아와서, 이 사진이 그럼 왜 고양이처럼 보이는지 인간의 입장에서 생각해봅시다. 아마 보송보송한 털, 조그만 몸집, 네개의 다리, 길쭉한 수염 같은 '고양이의 시각적 특성'을 보고 유추했을 것입니다. **그런데 컴퓨터는 이렇게 사람이 이해하는 방식으로 사진을 알아볼 수 없습니다.**
{:style="opacity: 0.90"}

![cat_matrix](/assets/img/2022-08-10/cat_matrix.png){: width="400"}{:style="display:block; margin-left:auto; margin-right:auto; padding:10px"}

&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;위의 숫자들은 **컴퓨터의 입장에서 본 고양이 사진**입니다. 우리가 보는 고양이 사진과 사뭇 다르죠? 컴퓨터가 인식하는 사진은 위 처럼 가로 픽셀 x 세로 픽셀 크기를 가지는 행렬의 형태로 나타납니다. 행렬의 각 원소의 값은 해당 픽셀이 얼마나 짙은가를 의미합니다. 컴퓨터는 이런 숫자들의 나열을 가지고 이제껏 사진을 바라보고 있던 것입니다. 
{:style="opacity: 0.90"}

&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;이 숫자들을 통해서는 고양이의 길쭉한 수염도, 보송보송한 털도 알아보기 힘들어 보입니다. 이쯤되면 컴퓨터가 사람처럼 ‘고양이의 시각적 특성’ 을 가지고 사진을 판단하는 것은 거의 불가능해 보입니다. 이렇게 사람이 보는 사진의 모습과 컴퓨터가 보는 사진의 모습 간에 차이가 존재하는 것을 ***Semantic Gap*** 이라고 합니다. (원래는 조금 더 넓은 의미의 용어이나, 이에 대해서는 추후에 다루도록 하겠습니다.)
{:style="opacity: 0.90; margin-bottom:80px"}

---

![quotes](/assets/img/quotation_mark.jpeg){: width="30"}{:style="display:block; margin-left:auto; margin-right:auto; margin-bottom:3px; margin-top:80px"}
## 이게 다 고양이라고요?
{:style="text-align:center; margin-top:0px; margin-bottom:40px"}

&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;이제는 컴퓨터가 왜 사진을 알아보기 힘들어 했는지 어느 정도 알 것 같습니다. Semantic gap으로 인해, 컴퓨터는 고양이를 구분하는데 시각적인 정보를 활용하기 어렵기 때문입니다. 그렇다면 컴퓨터에게 사진 대신 숫자 행렬을 학습하게 하면 안되는 걸까요? 고양이었던 숫자 행렬을 외우게 만들어서, 비슷한 숫자 행렬을 가지는 사진을 고양이라고 인식하게 만들면 안될까요?
{:style="opacity: 0.90"}

&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;애석하게도, 같은 고양이라고 해서 비슷한 숫자 행렬로 나타나는 것은 아닙니다. 다음과 같은 문제들 때문입니다: 
{:style="opacity: 0.90"}

![cat_illumination](/assets/img/2022-08-10/cat_illumination.png){: width="250"}{:style="display:block; margin-left:auto; margin-right:auto; margin-top:40px"}
- ***Illumination***: 같은 고양이더라도 사진을 찍을 때 광원이 어디 있느냐에 따라서 매우 다른 사진이 될 수 있습니다.

![cat_deformation](/assets/img/2022-08-10/cat_deformation.png){: width="250"}{:style="display:block; margin-left:auto; margin-right:auto; margin-top:40px"}
- ***Deformation***: 같은 고양이더라도 어떤 자세를 하고 있느냐에 따라서 매우 다른 사진이 될 수 있습니다.
<!-- {:style="text-align:center"} -->

![cat_occlusion](/assets/img/2022-08-10/cat_occlusion.png){: width="250"}{:style="display:block; margin-left:auto; margin-right:auto; margin-top:40px"}
- ***Occlusion***: 같은 고양이더라도 신체의 일부만 보일 수도 있습니다.
<!-- {:style="text-align:center"} -->

![cat_background](/assets/img/2022-08-10/cat_background.png){: width="250"}{:style="display:block; margin-left:auto; margin-right:auto; margin-top:40px"}
- ***Background clutter***: 같은 고양이더라도 배경의 차이에 따라 사진이 다르게 나타날 수 있습니다. 특히 배경과 고양이가 비슷한 경우 더욱 판단하기 어려워집니다.
<!-- {:style="text-align:center"} -->

![cat_variation](/assets/img/2022-08-10/cat_variation.png){: width="250"}{:style="display:block; margin-left:auto; margin-right:auto; margin-top:40px"}
- ***Deformation***: 고양이 안에서도 종류, 색깔별로 다른 고양이가 있습니다. 이렇게 다른 고양이들도 전부 고양이라고 판단할 수 있어야 합니다.
<!-- {:style="text-align:center"} -->

&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;결국 이와 같은 문제들로 인해 같은 고양이 사진도 굉장히 다양한 형태로 나타나게 됩니다. 따라서 숫자만 보고 고양이인지 아닌지를 판단해야 하는 컴퓨터의 입장에서는 더더욱 판단하기 어려울 겁니다. 비단 고양이 뿐만 아니라 개, 자동차 등 다른 모든 동물과 사물들을 사진에서 찾아내는 것도 위와 같은 문제가 있습니다. 이렇게 특정 사진이  어떤 사물 또는 동물의 사진인지를 컴퓨터로 분류하는 문제를 ***Image classification*** 문제라고 합니다. 고양이, 자동차, 개 등을 class의 종류로 보고, 이 이미지가 어떤 class에 해당하는지 알아내는 것이기 때문에 classification인 것입니다. 그리고 위에서 이 Image classification은 상당히 어려운 문제라는 것을 알 수 있었습니다. 
{:style="opacity: 0.90}

&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; 하지만 이 문제를 풀기 위해 다양하고 활발한 연구가 이뤄졌습니다. 그 중에서 가장 간단하고, 초창기에 제시된 방법은 바로 ***Nearest Neighbor*** 알고리즘 입니다.
{:style="opacity: 0.90; margin-bottom:80px"}

&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;

---
## Nearest Neighbor
{:style="text-align:center; margin-top:80px; margin-bottom: 0px"}
##### - 내 이웃을 보면 나를 알 수 있다.
{:style="text-align:center; margin-bottom:40px; margin-top:10px; opacity:0.60"}

&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; 유유상종(類類相從)이라는 말이 있습니다. 비슷한 사람들 끼리 서로 가까이 어울린다는 말이죠. 실제로 데이터의 세계에서도 비슷한 데이터라면 거리가 가까운 경향이 있습니다 (여기서 거리를 어떻게 측정하는지에 대해서는 잠시 후에 살펴보겠습니다.) Nearest Neighbor 는 데이터의 이러한 특성을 이용합니다. 정확한 컨셉은 다음과 같습니다.
{:style="opacity: 0.90"}
> 컴퓨터에게 다양한 학습용 사진 데이터 여러장을 전부 기억하게 한다. 그 후에 분류해야 하는 사진을 받으면 그 사진과 가장 거리가 가까운 학습 데이터를 기억해내서, 그 학습 데이터가 무엇에 대한 사진이었는지 말해준다.
{:style="opacity: 0.90"}

&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; 비록 컴퓨터가 보기에 사진 데이터는 숫자의 행렬로 보이겠지만, **같은 고양이 사진끼리는 그 거리가 가깝지 않겠나?** 라는 아이디어에서 출발한 방법입니다. 그렇다면 여기서 사진 데이터 간의 거리는 어떻게 측정하는 것일까요? 
{:style="opacity: 0.90; margin-bottom:50px"}

![graph](/assets/img/2022-08-10/graph.png){: width="700"}{:style="display:block; margin-left:auto; margin-right:auto; margin-top:30px"}

&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; 위 그림처럼 숫자 행렬을 쭉 펼쳐서 벡터로 만들면, 이를 좌표로 볼 수 있습니다. 즉, 사진 데이터 한 장 마다 하나의 좌표를 얻을 수 있습니다. nearest neighbor는 그 좌표끼리의 거리가 가까울 수록 비슷한 사진으로 보곘다는 것이죠. 예를 들면 알지 못하는 사진이 새로 들어왔을 때, 이전에 학습해놨던 사진 데이터 중에 현재 사진과 가장 거리가 가까운 사진이 강아지 사진이었다면, 새로 들어온 사진도 강아지라고 예측하는 것입니다. 이 예측 과정에서 '거리가 가장 가까운 이웃'을 사용하기 때문에 이름이 nearest neighbor인 것입니다.
{:style="opacity: 0.90"}

&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; Nearest neighbor 방법의 장점은 논리적으로 아주 간단하기 때문에 구현하기 쉽다는 것입니다. 다만 단점은 학습 데이터에 다른 데이터들과 매우 다른 이상치(Outlier)가 섞여 있는 경우, 예측력이 떨어진다는 것입니다. 이것이 어떤 의미인지 알아보도록 하겠습니다. 
{:style="opacity: 0.90; margin-bottom:50px"}

![nn_1](/assets/img/2022-08-10/nn_1.png){: width="300"}{:style="display:block; margin-left:auto; margin-right:auto; margin-top:30px"}

&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; 위 그림은 점과 색칠된 면으로 이루어져 있습니다. 각 점은 훈련에 사용한 데이터입니다. 그리고 색칠된 면은 nearest neighbor 알고리즘을 이용하여 훈련에 사용한 데이터를 가지고 모르는 데이터를 예측한 결과입니다. 같은 색깔로 칠해지면 같은 물체로 예측했다는 의미입니다. 각 점의 근처에 있는 부분들은 전부 그 점에 해당하는 색깔로 칠해져있는데요, nearest neighbor 알고리즘의 특성 상 학습한 데이터 중 가장 가까운 데이터와 동일하게 예측하기 때문입니다.
{:style="opacity: 0.90; margin-bottom:80px"}

![nn_2](/assets/img/2022-08-10/nn_2.png){: width="300"}{:style="display:block; margin-left:auto; margin-right:auto; margin-top:30px"}

&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; 그런데 빨간색으로 동그라미 친 그림 정중앙을 보면, 초록색 영역 안에 노란색 영역이 조그맣게 들어가 있는 것을 볼 수 있습니다. 이렇게 다소 뜬금없이 노란색 구간이 존재하게 된 이유는 해당 구간에 노란색 데이터 포인트가 하나 존재하기 때문입니다. 이렇게 전체 경향과 다소 맞지 않는 특이한 데이터를 이상치(outlier)라고 합니다. 
{:style="opacity: 0.90"}

&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; 이 이상치는 nearest neighbor 알고리즘에 악영향을 끼칩니다. 예를 들어 새로운 사진 데이터가 무엇에 대한 사진인지를 맞춰야 하는데, 이 사진 데이터가 그림의 동그라미 구간안에 위치하게 되었다고 합시다. 일반적으로 생각해 봤을 때 데이터 해당는 대부분 노란색 데이터로 둘러싸여 있으므로, 노란색 class로 보는 것이 알맞을 겁니다. 그런데 nearest neighbor 알고리즘은 '가장 가까운 이웃' 하나만 보고 판단하므로, 이 사진은 노란색 class 로 분류됩니다. 이런식으로 nearest neighbor 알고리즘은 훈련 데이터에 있는 몇 개의 outlier들로 인해 제대로 된 예측을 못하게 되는 문제가 발생할 수 있습니다. 그리고 이러한 문제를 해결하기 위해 나온 것이 K-Nearest Neighbor 알고리즘 입니다.
{:style="opacity: 0.90; margin-bottom:80px"}
## K-Nearest Neighbor
{:style="text-align:center; margin-top:80px; margin-bottom: 0px"}
##### - 내 이웃을 여러 명 보면 나를 더 잘 알 수 있다.
{:style="text-align:center; margin-bottom:40px; margin-top:10px; opacity:0.60"}

&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; K-nearest neighbor는 nearest neighbor 알고리즘과 거의 모든 부분에서 동일합니다. 다만 nearest neighbor가 가장 가까운 이웃만을 보고 결정한다면, K-Nearest Neighbor는 가장 가까운 K명의 이웃을 보고 그 중 가장 많은 것으로 결정한다는 점에서 차이가 있습니다. 즉 nearest neighbor는 K=1인 K-nearest neighbor와 같은 의미입니다.
{:style="opacity: 0.90; margin-bottom:50px"}

![knn_k1](/assets/img/2022-08-10/knn_k1.png){: width="250"}![knn_k3](/assets/img/2022-08-10/knn_k3.png){: width="250"}

&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; 위의 그림은 K=1인 경우와 K=3 인 경우의 K-nearest neighbor 를 적용한 모습입니다. K=1 인 경우에는 위에서 살펴본 것과 같이 가운데 있는 노란색 outlier가 전체 예측 양상에 악영향을 주고 있는 모습입니다. 
{:style="opacity: 0.90}

&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; 그런데 K=3의 경우를 살펴보면 조금 다릅니다. 노란색 훈련 데이터 포인트가 여전히 존재하지만, 그 주변의 예측값에 해당하는 면적은 초록색으로 나타납니다. 이것은 예측을 수행할 때 이웃하는 한 개의 데이터만 보는 것이 아니라 여러개를 보기 때문에, 노란색 데이터 옆의 초록색 데이터들이 예측에 반영되었기 떄문입니다.
{:style="opacity: 0.90}

&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; 이와 비슷한 원리로 K=1일 때 삐죽삐죽하게 튀어나와있던 영역들이, K=3에서는 다소 완만하게 정돈이 된 모습을 보입니다. 이렇게 K-nearest neighbor는 outlier의 영향을 덜 받고, 좀 더 일관성 있는 결과를 제공할 수 있기 때문에 nearest neighbor보다 더 나은 모습을 보입니다.
{:style="opacity: 0.90; margin-bottom:80px"}



